Support estimators
========
We provide implementation of our [rate-optimal estimators](https://arxiv.org/abs/1504.01227) and some classical estimators in both Python and C++. 
This is a tutorial for both software users and developers whoever want to use support estimators! 


Table of contents
========
* [Table of contents](#table-of-contents)
* [Python](#python)
* [C++](#c)
* [References](#reference)

Python
=====
This Python code works on Python3, and uses [Numpy](http://www.numpy.org), the fundamental package for scientific computing with Python, and its core package [SciPy](https://www.scipy.org/scipylib/index.html).
Make sure Python3, Numpy and SciPy are properly installed before using this code. 

* [Instruction for installing Python3](https://docs.python.org/3/using/index.html)
* [Instruction for installing Numpy and SciPy](https://www.scipy.org/install.html)

Basic script
-------
Here is an example on how to use support estimators in Python:
```python
>>> from support import *
>>> support = Support(pmin=1e-5)
>>> fin = [[1,2910],[2,45]]
>>> support.estimate(fin)
23722.435544392072
```
* ```from support import *``` imports all functions from *support.py*;
* ```support = Support(pmin=1e-5)``` initializes a support estimator with non-zero probabilities lower bounded by 1e-5. 
* ```fin = [[1,2910],[2,45]]``` is the fingerprint, represented by a list of tuples. This means 2910 symobols appeared exactly once, and 45 symbols appeared exactly twice. 
* ```support.estimate(fin)``` produces the support estimate using our rate-optimal estimator.

Functions
------
### Samples statistics
The support estimator requires an input of fingerprint. 
In case of raw data, we have functions for this statistics:
* ```sample_to_fin(sample)``` returns fingerprints of samples
  * input: a list of samples 
  * output: a list of tuples (fingerprints)
* ```hist_to_fin(hist)``` returns fingerprints from histogram (number of appearances/frequency counts)
  * input: a list of frequencies
  * output: a list of tuples (fingerprints)

### Other estimators
We implemented classical support estimators:  

* ```support.estimate_plug(fin)```: plug-in estimator
* ```support.estimate_turing_good(fin)```: Good-Turing estimator
* ```support.estimate_chao1(fin)```: Chao 1 estimator
* ```support.estimate_jackknife1(fin)```: First-order Jackknife estimator
* ```support.estimate_chao_lee1(fin)```: Chao-Lee estimator 1
* ```support.estimate_chao_lee2(fin)```: Chao-Lee estimator 2


Comprehensive script
---------
We provide ```main.py``` as an example script to tune parameters in our support estimator.
It can also be used directly as a estimator software working on data files!  
Type ```python3 main.py -pmin 1e-5 -fin fin_sample.txt``` or ```python3 main.py -pmin 1e-5 -hist hist_sample.txt``` to experiment on the fingerprint "fin\_sample.txt" or histogram "hist\_sample.txt" respectively, which are both the statistic of 3,000 samples generated by the uniform distribution over 100,000 symbols. 

### Program arguments

#### Main arguments:

* ```-pmin float```: set a lower bound on non-zero probabilities. 
* ```-fin str```: set fingerprint input file. 
  Each line of file consists of two numbers: frequency *j*, the number of symbols that appears exactly *j* times.
* ```-hist str```: set histogram input file. 
  Each line of file consists of only one number: frequency *j*. Symbols are not needed.
* *k* must be provided. 
  Either *fin* or *hist* must be provided.
  If both *fin* and *hist* are provided, only *fin* will be read.
  
#### Optional arguments:

* ```-L int```: set polynomial degree. Default *L=0.45 log (1/pmin)*.
* ```-M float```: set the right endpoint of approximation interval. Default *M=0.5 log (1/pmin)*.
* The parameters above can be combined, e.g., ```./entropy -pmin 1e-5 -fin fin_sample.txt -L 5 -M 6```.
* ``` --help``` or ```-h```: see the list of arguments.







C++
====

## Compile and run
Check out all source code, including the Makefile and .txt files.

Type ```make``` to compile the sources, you will get executable file *"support"*.

Type ```./support -pmin=1e-5 -fin=fin_sample.txt``` or ```./support -pmin=1e-5 -hist=hist_sample.txt``` to experiment on the fingerprint "fin\_sample.txt" or histogram "hist\_sample.txt" respectively, which are both the statistic of 3,000 samples generated by the uniform distribution over 100,000 symbols. 

### Program arguments

#### Main arguments:

* ```-pmin=number```: set minimum mass. 
* ```-fin=filename```: set fingerprint input file. 
  Each line of file consists of two numbers: frequency *j*, the number of symbols that appears exactly *j* times.
* ```-hist=filename```: set histogram input file. 
  Each line of file consists of only one number: frequency *j*. Symbols are not needed.
* *pmin* must be provided. 
  Either *fin* or *hist* must be provided.
  If both *fin* and *hist* are provided, only *fin* will be read.
  
#### Optional arguments:

* ```-L=number```: set polynomial degree. Default *L=0.45 log (1/pmin)*.
* ```-M=number```: set the right endpoint of approximation interval. Default *M=0.5 log (1/pmin)*.
* The parameters above can be combined, e.g., ```./support -pmin=1e-5 -fin=fin_sample.txt -L=5 -M=6```.
* Type ```./support -help``` or ```./support -h``` to see the list of arguments.


## More for developers
For developer who want to write a new test scratch to test the support estimator, follow the example test scratch *main_test.cpp*.
After compiling the source ```make```, this example gives you the executable file *"test"*.
Run with command ```./test```.


### Support estimator class: *Support*
Work flow: 

1. Configure estimator: require *pmin*. Optional configurations: 
  * **setDegree(int L)**: the degree of polynomial is L.
  * **setInterval(int M)**: the approximation interval is [0,M/n], where n is the sample size.
2. Input data: fingerprint or histogram, either from file or from vectors. Use one of the following: 
  * **setFin( filename )**: each line of file consists of two numbers: frequency *j*, the number of symbols that appears exactly *j* times.
  * **setFin( freq, count )**: input two vectors of the same length: *freq[i]* represents frequency, and *count[i]* counts the number of symbols that appear exactly *freq[i]* times. 
  * **setHist( filename )**: each line of file consists of one number: frequency *j*. Symbols are not needed.
  * **setHist( freq )**: input one vector with frequencies.
3. Output various estimates: 
  * **estimate()**: our polynomial estimator
  * **estimate_plug()**: plug-in estimator
  * **estimate_TG()**: Good-Turing estimator
  * **estimate_Chao1()**: Chao 1 estimator
  * **estimate_J1()**: First-order Jackknife estimator
  * **estimate_CL1()**: Chao-Lee estimator 1
  * **estimate_CL2()**: Chao-Lee estimator 2



### Synthetic data experiments
For those who want to generate synthetic samples within C++, you can refer to the standard [random number generator facilities](http://www.cplusplus.com/reference/random/).
There are examples to generate random numbers according to different types of distributions.
If the distribution is not yet provided, you can use the general [discrete distribution](http://www.cplusplus.com/reference/random/discrete\_distribution/).
There are several ways to [construct discrete distributions](http://www.cplusplus.com/reference/random/discrete\_distribution/discrete\_distribution/).


## Reference
For detailed explanation of parameters, please refer to our paper [Chebyshev polynomials, moment matching, and optimal estimation of the unseen, arXiv:1504.01227](https://arxiv.org/abs/1504.01227).
The parameters described in the paper are: *L=c<sub>0</sub> log k, M=c<sub>1</sub> log k*, where *k=1/pmin*.
In the experiment section of the paper, the default values are *L=0.45 log k, M=0.5 log k*.